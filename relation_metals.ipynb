{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the feature functions from CSV and trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mg', 'Na', 'Cu', 'Ca', 'Li', 'Al', 'Ni', 'Mn'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"features/mm_all.csv\")\n",
    "\n",
    "# Save to a CSV file\n",
    "molecules = df['Mol'].values\n",
    "\n",
    "\n",
    "molecules = molecules\n",
    "molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size Modification and adding parameters to Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mol</th>\n",
       "      <th>Pol</th>\n",
       "      <th>Rad</th>\n",
       "      <th>CN</th>\n",
       "      <th>Ion</th>\n",
       "      <th>EN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mg</td>\n",
       "      <td>71.20</td>\n",
       "      <td>160</td>\n",
       "      <td>8</td>\n",
       "      <td>7.646</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na</td>\n",
       "      <td>162.70</td>\n",
       "      <td>157</td>\n",
       "      <td>8</td>\n",
       "      <td>5.139</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cu</td>\n",
       "      <td>46.50</td>\n",
       "      <td>128</td>\n",
       "      <td>12</td>\n",
       "      <td>7.726</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ca</td>\n",
       "      <td>160.80</td>\n",
       "      <td>200</td>\n",
       "      <td>8</td>\n",
       "      <td>6.113</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Li</td>\n",
       "      <td>164.11</td>\n",
       "      <td>182</td>\n",
       "      <td>8</td>\n",
       "      <td>5.392</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Al</td>\n",
       "      <td>57.80</td>\n",
       "      <td>184</td>\n",
       "      <td>12</td>\n",
       "      <td>5.986</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ni</td>\n",
       "      <td>49.00</td>\n",
       "      <td>163</td>\n",
       "      <td>12</td>\n",
       "      <td>7.640</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mn</td>\n",
       "      <td>68.00</td>\n",
       "      <td>197</td>\n",
       "      <td>8</td>\n",
       "      <td>7.434</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Mol     Pol  Rad  CN    Ion    EN\n",
       "0  Mg   71.20  160   8  7.646  1.31\n",
       "1  Na  162.70  157   8  5.139  0.93\n",
       "2  Cu   46.50  128  12  7.726  1.91\n",
       "3  Ca  160.80  200   8  6.113  1.00\n",
       "4  Li  164.11  182   8  5.392  0.98\n",
       "5  Al   57.80  184  12  5.986  1.61\n",
       "6  Ni   49.00  163  12  7.640  1.91\n",
       "7  Mn   68.00  197   8  7.434  1.55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.iloc[:-1, :]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.144355598718082,\n",
       " 25.02717771580682,\n",
       " 5.118879491233692,\n",
       " 22.814559268959076,\n",
       " 25.719392847659723,\n",
       " 2.9222363463284893,\n",
       " 10.553895436793855,\n",
       " 15.857470042410599]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%store -r res\n",
    "res \n",
    "\n",
    "# res = res[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.144355598718082,\n",
       " 25.02717771580682,\n",
       " 5.118879491233692,\n",
       " 22.814559268959076,\n",
       " 25.719392847659723,\n",
       " 2.9222363463284893,\n",
       " 10.553895436793855,\n",
       " 15.857470042410599]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## always inverse of EN_A\n",
    "# res = df['EA_A']/np.array(res)\n",
    "\n",
    "## always inverse of delta EN\n",
    "\n",
    "## always inverse of pol_A ( anion polarisation)\n",
    "\n",
    "## remove df['EA_A'] from the dataframe\n",
    "# df = df.drop(columns=['EA_A'])\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:,1:]\n",
    "\n",
    "\n",
    "## always inverse of EN_A\n",
    "\n",
    "# # df['Diff_rad'] = df['RadV_A'] - df['RadV_C']\n",
    "\n",
    "\n",
    "# df['Sum_ion'] = df['Ion_C'] + df['Ion_A']\n",
    "# df['Abs_diff_ion'] = abs(df['Ion_C'] - df['Ion_A'])\n",
    "\n",
    "# df.drop(columns=['Rad','EN'], inplace=True)\n",
    "\n",
    "\n",
    "# # Adding sqrt values for each column\n",
    "for col in df.columns:\n",
    "    # Make sure the column is numeric before applying sqrt\n",
    "    if pd.api.types.is_numeric_dtype(df[col]):\n",
    "        df[f'{col}_sqrt'] = np.sqrt(abs(df[col]))\n",
    "        df[f'{col}_squared'] = np.square(df[col])\n",
    "\n",
    "\n",
    "# df['cal'] = 1/df['Pol_squared']\n",
    "# df['cal'] = df['cal']/df['Ion_squared']\n",
    "# df['cal'] = df['cal']*df['Pol_sqrt']\n",
    "# df['cal'] = df['cal']/df['EN']\n",
    "\n",
    "\n",
    "# df.drop(columns=['Pol_squared', 'Ion_squared', 'Rad_squared','EN_squared','Rad_sqrt','Pol_sqrt'], inplace=True)\n",
    "# df.drop(columns=['Pol_squared', 'Ion_squared', 'Rad_squared','Rad_sqrt','Pol_sqrt','EN_sqrt'], inplace=True)\n",
    "# df.drop(columns=['Pol_sqrt', 'Rad_squared','EN_squared','Rad_sqrt','Pol_sqrt','CN_squared','Rad'], inplace=True)\n",
    "# df.drop(columns=['Rad','Rad_squared','Pol','CN_squared','EN','EN_squared','EN_sqrt'], inplace=True)   # good results\n",
    "# df.drop(columns=['Pol_squared','Ion_squared','Rad','Rad_sqrt','Rad_squared','EN'], inplace=True)   # good results\n",
    "\n",
    "# df.drop(columns=['Rad','Pol_squared','Ion','Ion_sqrt','Pol_sqrt'], inplace=True)   # good results\n",
    "\n",
    "# df['sum_ion'] = df['Ion_C'] + df['Ion_A']\n",
    "# # df['diff_ion'] = df['Ion_C'] - df['Ion_A']\n",
    "\n",
    "# drop all cols except calc\n",
    "# df['Pol_cubed'] = df['Pol_squared'] * df['Pol']\n",
    "# df['Ion_cubed'] = df['Ion_squared'] * df['Ion']\n",
    "# df['CN_cubed'] = df['CN_squared'] * df['CN']\n",
    "# df = df[['Ion','Ion_cubed','Pol','Pol_cubed','CN']]\n",
    "df = df.drop(columns=['EN','EN_squared','EN_sqrt'])\n",
    "# df.drop(columns=)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making the combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_combinations_df(params_df, param_names):\n",
    "    results = []\n",
    "\n",
    "    # Convert all parameter values to numeric, coercing errors to NaN\n",
    "    params_df = params_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Precompute inverses of all parameters\n",
    "    params_inv_df = params_df.applymap(lambda x: np.power(float(x), -1) if pd.notnull(x) and x != 0 else np.nan)\n",
    "    params_inv_df.columns = [f\"{name}^(-1)\" for name in param_names]\n",
    "\n",
    "    # Combine original parameters and their inverses\n",
    "    combined_params_df = pd.concat([params_df, params_inv_df], axis=1)\n",
    "    combined_param_names = list(combined_params_df.columns)\n",
    "\n",
    "    # Precompute invalid pairs (parameter and its inverse)\n",
    "    invalid_pairs = {f\"{name}^(-1)\": name for name in param_names}\n",
    "    invalid_pairs.update({name: f\"{name}^(-1)\" for name in param_names})\n",
    "\n",
    "    # Generate all subsets of parameters (combinations)\n",
    "    for r in range(1, len(combined_param_names) + 1):\n",
    "        for subset_indices in itertools.combinations(range(len(combined_param_names)), r):\n",
    "\n",
    "            subset_names = [combined_param_names[i] for i in subset_indices]\n",
    "\n",
    "            # Skip invalid subsets early\n",
    "            if any(invalid_pairs.get(name) in subset_names for name in subset_names):\n",
    "                continue\n",
    "\n",
    "            # Select the subset DataFrame\n",
    "            subset = combined_params_df[subset_names]\n",
    "\n",
    "            # Replace NaN values with 0\n",
    "            subset = subset.fillna(0)\n",
    "\n",
    "            # Compute results for valid subsets\n",
    "            expr_str = \" * \".join(subset_names)\n",
    "            expr_val = subset.prod(axis=1)\n",
    "            results.append((expr_str, expr_val))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def process_combinations_chunk(args):\n",
    "    combined_params_df, combined_param_names, param_names, indices_chunk = args\n",
    "    results = []\n",
    "\n",
    "    for indices in indices_chunk:\n",
    "        subset_names = [combined_param_names[i] for i in indices]\n",
    "        subset = combined_params_df[subset_names]\n",
    "\n",
    "        # Replace NaN values with 0\n",
    "        subset = subset.fillna(0)\n",
    "\n",
    "        # Check if both a parameter and its inverse are in the subset\n",
    "        invalid = False\n",
    "        for name in subset_names:\n",
    "            if name.endswith(\"^(-1)\") and name[:-5] in subset_names:\n",
    "                invalid = True\n",
    "                break\n",
    "            elif name in param_names and f\"{name}^(-1)\" in subset_names:\n",
    "                invalid = True\n",
    "                break\n",
    "\n",
    "        if not invalid:\n",
    "            # Compute results for valid subsets\n",
    "            expr_str = \" * \".join(subset_names)\n",
    "            expr_val = subset.prod(axis=1)\n",
    "            results.append((expr_str, expr_val))\n",
    "\n",
    "    return results\n",
    "\n",
    "def generate_combinations_df_parallel(params_df, param_names):\n",
    "    # Convert all parameter values to numeric, coercing errors to NaN\n",
    "    params_df = params_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Precompute inverses of all parameters\n",
    "    params_inv_df = params_df.applymap(lambda x: np.power(float(x), -1) if pd.notnull(x) and x != 0 else np.nan)\n",
    "    params_inv_df.columns = [f\"{name}^(-1)\" for name in param_names]\n",
    "\n",
    "    # Combine original parameters and their inverses\n",
    "    combined_params_df = pd.concat([params_df, params_inv_df], axis=1)\n",
    "    combined_param_names = list(combined_params_df.columns)\n",
    "\n",
    "    # Generate all subsets of parameter indices\n",
    "    all_combinations = [\n",
    "        indices for r in range(1, len(combined_param_names) + 1)\n",
    "        for indices in itertools.combinations(range(len(combined_param_names)), r)\n",
    "    ]\n",
    "\n",
    "    # Divide all_combinations into chunks\n",
    "    num_workers = min(cpu_count(), len(all_combinations))\n",
    "    chunk_size = max(1, len(all_combinations) // num_workers)\n",
    "    chunks = [all_combinations[i:i + chunk_size] for i in range(0, len(all_combinations), chunk_size)]\n",
    "\n",
    "    print(f\"Using {num_workers} workers to process {len(all_combinations)} combinations in {len(chunks)} chunks\")\n",
    "\n",
    "    # Prepare arguments for parallel processing\n",
    "    args = [\n",
    "        (combined_params_df, combined_param_names, param_names, chunk)\n",
    "        for chunk in chunks\n",
    "    ]\n",
    "\n",
    "    # Use multiprocessing to process combinations in parallel\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        results = pool.map(process_combinations_chunk, args)\n",
    "\n",
    "    # Flatten results\n",
    "    flattened_results = [item for sublist in results for item in sublist]\n",
    "    return flattened_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeretor = []\n",
    "denomeretor = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_combinations_df(params_df, param_names, restricted_properties=None, restricted_to_inverses=None):\n",
    "    if restricted_properties is None:\n",
    "        restricted_properties = []\n",
    "    if restricted_to_inverses is None:\n",
    "        restricted_to_inverses = []\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Convert all parameter values to numeric, coercing errors to NaN\n",
    "    params_df = params_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Precompute inverses of all parameters\n",
    "    params_inv_df = params_df.applymap(lambda x: np.power(float(x), -1) if pd.notnull(x) and x != 0 else np.nan)\n",
    "    params_inv_df.columns = [f\"{name}^(-1)\" for name in param_names]\n",
    "\n",
    "    # Combine original parameters and their inverses\n",
    "    combined_params_df = pd.concat([params_df, params_inv_df], axis=1)\n",
    "    combined_param_names = list(combined_params_df.columns)\n",
    "\n",
    "     # Precompute invalid pairs (parameter and its inverse)\n",
    "    invalid_pairs = {f\"{name}^(-1)\": name for name in param_names}\n",
    "    invalid_pairs.update({name: f\"{name}^(-1)\" for name in param_names})\n",
    "    \n",
    "    # Generate all subsets of parameters (combinations)\n",
    "    for r in range(1, len(combined_param_names) + 1):\n",
    "        for subset_indices in itertools.combinations(range(len(combined_param_names)), r):\n",
    "            subset_names = [combined_param_names[i] for i in subset_indices]\n",
    "\n",
    "            # Replace NaN values with 0\n",
    "             # Skip invalid subsets early\n",
    "            if any(invalid_pairs.get(name) in subset_names for name in subset_names):\n",
    "                continue\n",
    "            \n",
    "            subset = combined_params_df[subset_names]\n",
    "            subset = subset.fillna(0)\n",
    "\n",
    "            # Check if both a parameter and its inverse are in the subset\n",
    "            invalid = False\n",
    "           \n",
    "            # Exclude subsets containing restricted inverses\n",
    "            for restricted in restricted_properties:\n",
    "                if f\"{restricted}^(-1)\" in subset_names:\n",
    "                    invalid = True\n",
    "                    break\n",
    "\n",
    "            # Ensure restricted properties only appear as inverses\n",
    "            for restricted in restricted_to_inverses:\n",
    "                if restricted in subset_names or (restricted not in param_names and f\"{restricted}^(-1)\" not in subset_names):\n",
    "                    invalid = True\n",
    "                    break\n",
    "\n",
    "            if invalid:\n",
    "                continue\n",
    "\n",
    "            # Compute results for valid subsets\n",
    "            expr_str = \" * \".join(subset_names)\n",
    "            expr_val = subset.prod(axis=1)\n",
    "            results.append((expr_str, expr_val))\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating expressions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zp/h52np6n918qd9v9139ls4z600000gn/T/ipykernel_74337/3888168962.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  params_inv_df = params_df.applymap(lambda x: np.power(float(x), -1) if pd.notnull(x) and x != 0 else np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expressions cached.\n",
      "(531440, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "takeSaved = False\n",
    "\n",
    "all_expressions = []\n",
    "expressions = []\n",
    "# Define file name to save/load the results\n",
    "cache_file = \"cached_expressions.pkl\"\n",
    "\n",
    "if os.path.exists(cache_file) and takeSaved:\n",
    "    # Load the cached results if they exist\n",
    "    expressions = pd.read_pickle(cache_file)\n",
    "    all_expressions = list(expressions.itertuples(index=False, name=None))\n",
    "    print(\"Loaded cached expressions.\")\n",
    "else:\n",
    "    # Perform the costly computation if cache does not exist\n",
    "    print(\"Calculating expressions...\")\n",
    "    param_names = list(df.columns)\n",
    "    all_expressions = generate_combinations_df(df.iloc[:, ], param_names, restricted_properties=numeretor, restricted_to_inverses=denomeretor)\n",
    "    expressions = pd.DataFrame(all_expressions, columns=['Expression', 'Value'])\n",
    "\n",
    "    # Save the results to cache\n",
    "    # expressions.to_pickle(cache_file)\n",
    "    print(\"Expressions cached.\")\n",
    "\n",
    "# Print the shape of the expressions DataFrame\n",
    "print(expressions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expression</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pol</td>\n",
       "      <td>0     71.20\n",
       "1    162.70\n",
       "2     46.50\n",
       "3    160.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rad</td>\n",
       "      <td>0    160\n",
       "1    157\n",
       "2    128\n",
       "3    200\n",
       "4    182\n",
       "5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CN</td>\n",
       "      <td>0     8\n",
       "1     8\n",
       "2    12\n",
       "3     8\n",
       "4     8\n",
       "5    1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ion</td>\n",
       "      <td>0    7.646\n",
       "1    5.139\n",
       "2    7.726\n",
       "3    6.113\n",
       "4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pol_sqrt</td>\n",
       "      <td>0     8.438009\n",
       "1    12.755391\n",
       "2     6.819091\n",
       "3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Expression                                              Value\n",
       "0        Pol  0     71.20\n",
       "1    162.70\n",
       "2     46.50\n",
       "3    160.8...\n",
       "1        Rad  0    160\n",
       "1    157\n",
       "2    128\n",
       "3    200\n",
       "4    182\n",
       "5...\n",
       "2         CN  0     8\n",
       "1     8\n",
       "2    12\n",
       "3     8\n",
       "4     8\n",
       "5    1...\n",
       "3        Ion  0    7.646\n",
       "1    5.139\n",
       "2    7.726\n",
       "3    6.113\n",
       "4 ...\n",
       "4   Pol_sqrt  0     8.438009\n",
       "1    12.755391\n",
       "2     6.819091\n",
       "3..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expressions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addition results to the combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_dict = {expr_str: expr_val for expr_str, expr_val in all_expressions}\n",
    "values = pd.DataFrame(values_dict)\n",
    "values['res'] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# correlation = values.corr()\n",
    "\n",
    "# correlation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results=correlation['res'].abs().sort_values(ascending=False)\n",
    "# print(results.iloc[0:100])\n",
    "# top_vars = results.iloc[1:20].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results=correlation['res'].abs().sort_values(ascending=False)\n",
    "# print(results.iloc[0:20])\n",
    "# top_vars = results.iloc[1:20].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = top_vars[0]\n",
    "\n",
    "# y = values[param]*1e10\n",
    "# x = values['res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error, r2_score\n",
    "\n",
    "# # Reshape x to a 2D array\n",
    "# x_reshaped = x.values.reshape(-1, 1)  # Convert x to a 2D array (n, 1)\n",
    "\n",
    "# # Create and fit the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(x_reshaped, y)\n",
    "\n",
    "# # Get the slope (coefficient) and intercept\n",
    "# slope = model.coef_[0]  # model.coef_ gives the slope of the line\n",
    "# intercept = model.intercept_  # model.intercept_ gives the intercept\n",
    "\n",
    "# # Predict y values using the linear model\n",
    "# y_pred = model.predict(x_reshaped)\n",
    "\n",
    "# # Calculate R^2, MSE, and MAPE\n",
    "# r_squared = r2_score(y, y_pred)\n",
    "# mse = mean_squared_error(y, y_pred)\n",
    "# mape = mean_absolute_percentage_error(y, y_pred)\n",
    "\n",
    "# # Display the equation of the line\n",
    "# equation = f\"y = {slope:.4f}x + {intercept:.4f}\"\n",
    "\n",
    "# # Plot the data points and the regression line\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(x, y, color='blue', label='Data points')\n",
    "# plt.plot(x, y_pred, color='red', label='Regression Line')\n",
    "# plt.title(f'Scatter Plot of x vs y with Linear Regression Line\\n{param}')\n",
    "# plt.xlabel('Percentage Error')\n",
    "# plt.ylabel('Function Value')\n",
    "# plt.grid()\n",
    "# plt.legend()\n",
    "\n",
    "# # Add text box with metrics\n",
    "# textstr = f\"$R^2$: {r_squared:.4f}\\nMSE: {mse:.4f} \\nMAPE: {mape:.4f}\\n{equation}\"\n",
    "# plt.gca().text(0.05, 0.25, textstr, transform=plt.gca().transAxes, fontsize=10,\n",
    "#                verticalalignment='top', bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8))\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "1. CN_sqrt * Ion_sqrt * Pol_sqrt^(-1) * Rad_sqrt^(-1) \n",
    "\n",
    "2. Rad_sqrt * CN_sqrt * Ion_sqrt * Rad^(-1) * Pol_sqrt^(-1)\n",
    "\n",
    "\n",
    "After adding alumninum relations changed \n",
    "\n",
    "1. Ion * Pol_sqrt * EN_sqrt * EN^(-1) * CN_sqrt^(-1)\n",
    "\n",
    "After adding Mn\n",
    "\n",
    "2. EN^(-1) * Pol_sqrt^(-1) * Pol_squared^(-1) * Ion_squared^(-1)  ( 97.1)\n",
    "\n",
    "Removing Ca \n",
    "\n",
    "3. EN * Pol_sqrt^(-1) * Pol_squared^(-1) * CN_sqrt^(-1) * Ion_squared^(-1) * EN_squared^(-1) (98.7)\n",
    "\n",
    "4. Pol_sqrt * Pol_squared^(-1) * Rad_sqrt^(-1) * CN_sqrt^(-1) * Ion_squared^(-1)  (98.7 less mse)\n",
    "\n",
    "\n",
    "\n",
    "Final Considered Result \n",
    "\n",
    "y = 1/ Pol^3 * 1/ Ion^3 * 1/CN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert your data to a DataFrame\n",
    "df = pd.DataFrame(all_expressions)\n",
    "\n",
    "# Assuming the column `1` contains lists of numbers\n",
    "# Expand the column with lists into separate columns\n",
    "expanded_columns = pd.DataFrame(df[1].tolist())\n",
    "\n",
    "# Concatenate the expanded columns back with the rest of the DataFrame\n",
    "df = pd.concat([df.drop(columns=[1]), expanded_columns], axis=1)\n",
    "\n",
    "df = df.T\n",
    "\n",
    "df.columns = df.iloc[0]  # Set the first row as column names\n",
    "df = df[1:]  # Drop the first row since it's now the header\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n",
    "res = pd.Series(res)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df\n",
    "y = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 41.21682347402992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importances:\n",
      "Pol * Rad * CN_squared * Pol_squared^(-1) * Rad_squared^(-1) * CN_sqrt^(-1) * Ion_sqrt^(-1) * Ion_squared^(-1): 0.1375\n",
      "Pol * Ion * Pol_squared * Rad_sqrt * Ion_squared * CN^(-1) * Pol_sqrt^(-1) * Rad_squared^(-1): 0.1114\n",
      "CN * Rad_squared * Ion_sqrt * Ion_squared * Rad^(-1) * Ion^(-1) * Pol_squared^(-1) * Rad_sqrt^(-1) * CN_sqrt^(-1): 0.0902\n",
      "CN * Pol_sqrt * Rad_sqrt * CN_squared * Ion_squared * Pol_squared^(-1) * CN_sqrt^(-1) * Ion_sqrt^(-1): 0.0731\n",
      "Pol * Rad * Pol_sqrt * Pol_squared * Rad_squared * Ion_sqrt * CN^(-1) * Ion^(-1) * CN_sqrt^(-1): 0.0592\n",
      "CN * Rad_sqrt * Rad_squared * Ion_sqrt * Ion_squared * Pol^(-1) * Rad^(-1) * Pol_sqrt^(-1) * CN_sqrt^(-1): 0.0479\n",
      "Rad * Pol_squared * CN_squared * Ion_squared * Pol_sqrt^(-1) * Rad_sqrt^(-1) * Rad_squared^(-1) * CN_sqrt^(-1): 0.0395\n",
      "Ion * Pol_sqrt * Rad_sqrt * CN_squared * Ion_sqrt * Ion_squared * Rad^(-1) * CN^(-1) * Pol_squared^(-1) * Rad_squared^(-1) * CN_sqrt^(-1): 0.0388\n",
      "Rad * Pol_squared * CN_squared * Ion_squared * Pol^(-1) * CN^(-1) * Ion^(-1) * Rad_sqrt^(-1) * Ion_sqrt^(-1): 0.0320\n",
      "CN * Pol_squared * Ion_squared * Rad^(-1) * CN_sqrt^(-1) * CN_squared^(-1) * Ion_sqrt^(-1): 0.0315\n",
      "Rad_squared * CN_squared * CN^(-1) * Ion^(-1) * Rad_sqrt^(-1) * CN_sqrt^(-1) * Ion_squared^(-1): 0.0259\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance values\n",
    "import numpy as np\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "features = X.columns  # Feature names\n",
    "\n",
    "# Combine into a dictionary\n",
    "importance_dict = {feature: importance for feature, importance in zip(features, feature_importances)}\n",
    "\n",
    "# Sort by importance\n",
    "sorted_importances = sorted(importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print feature importances\n",
    "print(\"Feature Importances:\")\n",
    "\n",
    "i=0\n",
    "for feature, importance in sorted_importances:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE): 146.03%\n",
      "\n",
      "Feature Importances (Coefficients):\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_sqrt * CN_squared * Ion_sqrt * Ion_squared: 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_squared * Ion_sqrt * Ion_squared: 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_sqrt * CN_squared * Ion_squared: 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_sqrt * Rad_squared * CN_sqrt * CN_squared * Ion_squared: -0.0000\n",
      "Pol * Rad * CN * Ion * Pol_squared * Rad_sqrt * Rad_squared * CN_sqrt * CN_squared * Ion_sqrt * Ion_squared: 0.0000\n",
      "Pol * Rad * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_sqrt * CN_squared * Ion_sqrt * Ion_squared: 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_squared * Ion_sqrt * Ion_squared * CN_sqrt^(-1): 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_squared * Ion_squared: 0.0000\n",
      "Pol * Rad * CN * Pol_sqrt * Pol_squared * Rad_squared * CN_sqrt * CN_squared * Ion_sqrt * Ion_squared: 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_sqrt * CN_squared * Ion_squared * Ion_sqrt^(-1): 0.0000\n",
      "Pol * Rad * CN * Ion * Pol_sqrt * Pol_squared * Rad_squared * CN_sqrt * CN_squared * Ion_sqrt * Ion_squared * Rad_sqrt^(-1): 0.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import pandas as pd\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute MAPE\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred) * 100  # MAPE in percentage\n",
    "\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "# Get feature importance (coefficients for linear regression)\n",
    "features = X.columns  # Feature names\n",
    "coefficients = model.coef_\n",
    "\n",
    "# Combine into a dictionary\n",
    "importance_dict = {feature: coef for feature, coef in zip(features, coefficients)}\n",
    "\n",
    "# Sort by importance\n",
    "sorted_importances = sorted(importance_dict.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Print feature importances (coefficients)\n",
    "\n",
    "i=0\n",
    "print(\"\\nFeature Importances (Coefficients):\")\n",
    "for feature, coef in sorted_importances:\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "    i+=1\n",
    "    if i>10:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
